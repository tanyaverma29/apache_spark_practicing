# Databricks notebook source
# MAGIC %md
# MAGIC ### PySpark ETL
# MAGIC In this tutorial we will learn basic ETL pipelines using pyspark. ETL stands for Extract, Transform & Load.
# MAGIC 
# MAGIC * Extract - Extracting data from a source to your storage. e.g csv to dataframe
# MAGIC * Tranform - applying transformation e.g. adding new column, rename column, change type, drop columns, derived columns, filter operations, joins etc.
# MAGIC * Load - Load back processed or transformed data to the sink/destination storage.
# MAGIC 
# MAGIC All the code is available in github, feel free to pull or fork the repository:
# MAGIC 
# MAGIC __https://github.com/martandsingh/ApacheSpark__
# MAGIC 
# MAGIC follow me on linkedin for more updates:
# MAGIC 
# MAGIC __https://www.linkedin.com/in/martandsays/__
# MAGIC 
# MAGIC ![PYSPARK_ETL](https://raw.githubusercontent.com/martandsingh/images/master/etl_banner.gif)

# COMMAND ----------


